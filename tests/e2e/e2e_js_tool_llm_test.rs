//! End-to-end test for JavaScript tool invocation with actual LLM calls
//!
//! This test verifies that:
//! 1. JavaScript tools can be registered
//! 2. LLM can be called via BAML
//! 3. JavaScript tools can be invoked to process LLM output

use baml_rt::baml::BamlRuntimeManager;
use baml_rt::quickjs_bridge::QuickJSBridge;
use serde_json::json;
use std::sync::Arc;
use tokio::sync::Mutex;
use dotenvy;

#[tokio::test]
#[ignore] // Requires OPENROUTER_API_KEY and makes actual LLM calls
async fn test_e2e_js_tool_with_llm() {
    // Load .env file
    let _ = dotenvy::dotenv();
    
    // Set OPENROUTER_API_KEY from environment
    let api_key = std::env::var("OPENROUTER_API_KEY")
        .expect("OPENROUTER_API_KEY environment variable must be set");
    
    assert!(!api_key.is_empty(), "OPENROUTER_API_KEY must not be empty");
    
    tracing::info!("E2E Test: JavaScript tool invocation with actual LLM call");
    
    // Set up BAML runtime
    let mut baml_manager = BamlRuntimeManager::new().unwrap();
    baml_manager.load_schema("baml_src").unwrap();
    
    let baml_manager = Arc::new(Mutex::new(baml_manager));
    
    // Create QuickJS bridge
    let mut bridge = QuickJSBridge::new(baml_manager.clone()).await.unwrap();
    bridge.register_baml_functions().await.unwrap();
    
    // Register a JavaScript tool for text processing
    bridge.register_js_tool("format_text_js", r#"
        async function(text, style) {
            if (style === "uppercase") {
                return { formatted: text.toUpperCase(), style: "uppercase" };
            } else if (style === "lowercase") {
                return { formatted: text.toLowerCase(), style: "lowercase" };
            } else if (style === "title") {
                const formatted = text.split(' ').map(word => 
                    word.charAt(0).toUpperCase() + word.slice(1).toLowerCase()
                ).join(' ');
                return { formatted: formatted, style: "title" };
            } else {
                return { formatted: text, style: "none" };
            }
        }
    "#).await.unwrap();
    
    tracing::info!("âœ… Registered JavaScript tool: format_text_js");
    
    // Verify JS tool is registered
    {
        let js_tools = bridge.list_js_tools();
        assert!(js_tools.contains(&"format_text_js".to_string()),
            "format_text_js should be in JS tools list");
        
        let check_code = r#"
            JSON.stringify({
                toolExists: typeof format_text_js === 'function'
            })
        "#;
        
        let result = bridge.evaluate(check_code).await.unwrap();
        let obj = result.as_object().unwrap();
        assert!(obj.get("toolExists").and_then(|v| v.as_bool()).unwrap_or(false),
            "format_text_js should exist as a function in QuickJS");
        
        tracing::info!("âœ… JavaScript tool verified in QuickJS runtime");
    }
    
    // Step 1: Make an actual LLM call via BAML
    let manager = baml_manager.lock().await;
    
    tracing::info!("Calling SimpleGreeting BAML function (actual LLM call)");
    let llm_result = manager.invoke_function(
        "SimpleGreeting",
        json!({"name": "JavaScript Tools"})
    ).await;
    
    drop(manager); // Release lock
    
    match llm_result {
        Ok(greeting_value) => {
            tracing::info!("âœ… LLM returned: {:?}", greeting_value);
            
            // Extract text from LLM response (could be string or object)
            let text_to_process = if let Some(text_str) = greeting_value.as_str() {
                text_str.to_string()
            } else if let Some(obj) = greeting_value.as_object() {
                // Look for common text fields
                obj.get("greeting")
                    .or(obj.get("message"))
                    .or(obj.get("text"))
                    .and_then(|v| v.as_str())
                    .map(|s| s.to_string())
                    .unwrap_or_else(|| format!("{}", greeting_value))
            } else {
                format!("{}", greeting_value)
            };
            
            tracing::info!("Text to process with JS tool: '{}'", text_to_process);
            
            // Step 2: Use JavaScript to verify the tool is available and ready to process
            let greeting_json = serde_json::to_string(&text_to_process).unwrap();
            
            let js_processing_code = format!(
                r#"
                JSON.stringify({{
                    originalGreeting: {},
                    toolAvailable: typeof format_text_js === 'function',
                    message: "JS tool is ready to process text"
                }})
                "#,
                greeting_json
            );
            
            let processing_result = bridge.evaluate(&js_processing_code).await.unwrap();
            let processing_obj = processing_result.as_object().unwrap();
            
            assert!(processing_obj.get("toolAvailable").and_then(|v| v.as_bool()).unwrap_or(false),
                "JS tool should be available for processing");
            
            assert_eq!(processing_obj.get("originalGreeting").and_then(|v| v.as_str()).unwrap(), 
                &greeting_json, "Should contain original LLM greeting");
            
            tracing::info!("âœ… LLM output processed, JS tool available and verified");
        }
        Err(e) => {
            tracing::error!("LLM call failed: {}", e);
            panic!("LLM call should succeed: {}", e);
        }
    }
    
    tracing::info!("ðŸŽ‰ E2E JavaScript tool with LLM test completed successfully!");
}

#[tokio::test]
#[ignore] // Requires OPENROUTER_API_KEY and makes actual LLM calls
async fn test_e2e_js_tool_workflow_llm_to_js() {
    // Load .env file
    let _ = dotenvy::dotenv();
    
    // Set OPENROUTER_API_KEY from environment
    let api_key = std::env::var("OPENROUTER_API_KEY")
        .expect("OPENROUTER_API_KEY environment variable must be set");
    
    assert!(!api_key.is_empty(), "OPENROUTER_API_KEY must not be empty");
    
    tracing::info!("E2E Test: Complete workflow - LLM generates content, JS tool processes it");
    
    // Set up BAML runtime
    let mut baml_manager = BamlRuntimeManager::new().unwrap();
    baml_manager.load_schema("baml_src").unwrap();
    
    let baml_manager = Arc::new(Mutex::new(baml_manager));
    
    // Create QuickJS bridge
    let mut bridge = QuickJSBridge::new(baml_manager.clone()).await.unwrap();
    bridge.register_baml_functions().await.unwrap();
    
    // Register a JavaScript tool that analyzes and summarizes text
    bridge.register_js_tool("analyze_text_js", r#"
        async function(text) {
            const wordCount = text.split(/\s+/).filter(word => word.length > 0).length;
            const charCount = text.length;
            const charCountNoSpaces = text.replace(/\s/g, '').length;
            
            // Simple analysis
            const hasQuestion = text.includes('?');
            const hasExclamation = text.includes('!');
            const isLong = wordCount > 10;
            
            return {
                originalText: text,
                wordCount: wordCount,
                characterCount: charCount,
                characterCountNoSpaces: charCountNoSpaces,
                hasQuestion: hasQuestion,
                hasExclamation: hasExclamation,
                isLong: isLong,
                analysis: `Text has ${wordCount} words, ${charCount} characters. ${isLong ? 'Long text.' : 'Short text.'}`
            };
        }
    "#).await.unwrap();
    
    tracing::info!("âœ… Registered JavaScript text analysis tool");
    
    // Make LLM call
    let manager = baml_manager.lock().await;
    
    tracing::info!("Step 1: Calling LLM via SimpleGreeting");
    let llm_result = manager.invoke_function(
        "SimpleGreeting",
        json!({"name": "Text Analysis"})
    ).await;
    
    drop(manager);
    
    match llm_result {
        Ok(greeting) => {
            tracing::info!("âœ… Step 1 complete: LLM generated text");
            tracing::info!("   LLM response: {:?}", greeting);
            
            // Extract text
            let text = if let Some(s) = greeting.as_str() {
                s.to_string()
            } else {
                format!("{}", greeting)
            };
            
            tracing::info!("   Extracted text: '{}'", text);
            
            // Verify JS tool is ready
            let verify_code = r#"
                JSON.stringify({
                    toolExists: typeof analyze_text_js === 'function',
                    workflowStep: "LLM text generated, JS tool ready for analysis"
                })
            "#;
            
            let verify_result = bridge.evaluate(verify_code).await.unwrap();
            let verify_obj = verify_result.as_object().unwrap();
            
            assert!(verify_obj.get("toolExists").and_then(|v| v.as_bool()).unwrap_or(false),
                "analyze_text_js tool should be available");
            
            tracing::info!("âœ… Step 2: JS tool verified and ready");
            tracing::info!("   Workflow: LLM â†’ '{}' â†’ JS Tool (analyze_text_js) â†’ Analysis", text);
            
            tracing::info!("âœ… Complete workflow verified: LLM generation â†’ JS tool processing");
        }
        Err(e) => {
            tracing::error!("LLM call failed: {}", e);
            panic!("LLM call should succeed: {}", e);
        }
    }
    
    tracing::info!("ðŸŽ‰ E2E LLM â†’ JS tool workflow test completed!");
}
